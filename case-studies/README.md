# Case Studies

This section contains detailed case studies of specific adversarial prompting attempts, safety failures, and defensive successes in LLM systems.

## Contents

Each case study typically includes:
- Background and context
- Methodology and approach
- Findings and results
- Implications for AI safety
- Mitigations and defenses

## Case Studies

- [Jailbreak Case Study Template](jailbreak-case-study-template.md)
- [Safety Failure Analysis Template](safety-failure-analysis-template.md)
- [Defensive Success Template](defensive-success-template.md)

---

*This is a living document. Case studies will be added as research progresses.*
